---
title: "Exercise 2 -- Gaussian Bayesian Updating and the Rescorla-Wagner Model"
subtitle: "15.838: Consumer Cognition"
date: "March 4, 2025"
author: Josh White
execute:
  warning: false
  cache: false
format:
  pdf:
    #toc: true
    df-print: kable
    fig-align: center
    fig-width: 4
    fig-height: 4
    fontsize: 9pt
    monofont: 'Source Code Pro'
    monofontoptions: 
    - Scale=0.666
#. Following allows for code and output to be wrapped .#
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
      % Note: setting commandchars=\\\{\} here will cause an error 
    }
---

```{r}
#| label: setup
#| echo: false
#| warning: false

# Load packages
library(tidyverse)
library(ggdist)

# set ggplot theme
theme_set(
  theme_classic() + 
  theme(
    legend.position = "bottom", 
    text = element_text(size = 9)
  )
)

#set figure size in chunks
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.align = "center")
```

## Question 1

To derive the Rescorla-Wagner update rule from Gaussian bayesian updating (with fixed variance), we first start be expressing this in terms of precision, given the known results that this is cojugate update. 
To derive the Rescorla-Wagner update rule from Gaussian Bayesian updating (with fixed variance), we first start be expressing the conjugate posterior after $n$ observations, in terms of precision of the reward $\tau_r$, the reward trajectory, $r_t$ $\forall t\in [1, n]$, and prior mean, $\mu_0$ and precision, $\tau_0$:

$$
\mu_{n} = \frac{\tau_0 \mu_0 + \tau_r \sum_{t = 1}^n r_t}{\tau_t + n\tau_r}
$$
Now we take this to the case of a single update from $t$ to $t+1$ (i.e., $n = 1$) and rearrange:

\begin{align*}
\mu_{t+1} &= \frac{\tau_t \mu_t + \tau_r r_t}{\tau_t + \tau_r} \\
\mu_{t+1} &= \mu_t \frac{\tau_t}{\tau_t + \tau_r} + r_t \frac{\tau_r}{\tau_t + \tau_r} \\
\mu_{t+1} &= \mu_t \frac{\tau_t}{\tau_t + \tau_r} + \mu_t \frac{\tau_r}{\tau_t + \tau_r} - \mu_t \frac{\tau_r}{\tau_t + \tau_r} + r_t \frac{\tau_r}{\tau_t + \tau_r}  \mu \\
\mu_{t+1} &= \mu_t \left(\frac{\tau_t}{\tau_t + \tau_r} + \frac{\tau_r}{\tau_t + \tau_r} \right) - \mu_t \frac{\tau_r}{\tau_t + \tau_r} + r_t \frac{\tau_r}{\tau_t + \tau_r}  \mu \\
\mu_{t+1} &= \mu_t - \mu_t \frac{\tau_r}{\tau_t + \tau_r} + r_t \frac{\tau_r}{\tau_t + \tau_r} \\
\mu_{t+1} &= \mu_t + \frac{\tau_r}{\tau_t + \tau_r} (r_t - \mu_t) \quad \\
\end{align*}


This gives us the update in the same functional form as in the Rescorla-Wagner model, where the learning rate is $\alpha = \frac{\tau_r}{\tau_t + \tau_r}$, and the prediction error is $\delta_t = r_t - \mu_t$. Finally, we rearrange to get the result in terms of variance:

$$
\alpha = \frac{\tau_r}{\tau_t + \tau_r} = \frac{1/\sigma_r^2}{1/\sigma_t^2 + 1/\sigma_r^2} = \frac{\sigma_t^2}{\sigma_t^2 + \sigma_r^2}
$$

There are a few things to note about this:

1. The learning rate fundamentally depends on uncertainty. When the prior variance is high relative to the reward variance, the learning rate is high -- a Bayesian agent relies heavily on new observations. When the reward variance is high relative to the prior variance, the learning rate is low -- a Bayesian agent relies more on prior beliefs, as the reward is comparatively less informative.
2. The learning rate changes over time -- as the posterior variance is reduced over updates, so is the learning rate. This means that a rational agent updates their beliefs less over time.  This is in contrast to the Rescorla-Wagner model and many instantiations of RL algorithms, where the learning rate is often treated as fixed (although note the Robbins-Monro conditions for convergence of tabular Q-learning).
3. This grounds Rescorla Wagner and TD(0) in a Bayesian framework, where the learning rate is a function of the relative uncertainty of the prior and the reward. This is a more general framework that can be extended to other models (e.g., TD($\lambda$) or other Bayesian models with different likelihoods or priors).

\newpage

## Question 2

### (a)

First set parameters, and write function to do iterative Bayesian updates for n time steps.

```{r}
n <- 50      # number of time steps (T often Boolean in R)
v_true <- 10 # true mean
mu_0 <- 0    # prior mean
var_0 <- 25  # prior variance
var_r <- 16  # reward/likelihood variance

bayesian_update <- function(n, v_true, mu_0, var_0, var_r) {
  # convert var to precision
  tau_0 <- 1 / var_0 
  tau_r <- 1 / var_r
    
  # intialize relevant vars
  mu <- numeric(n + 1) # posterior at each timestep
  mu[1] <- mu_0        # at t = 0, posterior is prior
  
  tau <- numeric(n)     # precision at each timestep
  alpha <- numeric(n)   # learning rate at each timestep
  
  # get reward at each time step
  r <- rnorm(n, mean = v_true, sd = sqrt(var_r))
  
  # update posterior at each time step
  for (t in seq_len(n)) {
      tau[t] <- tau_0 + t*tau_r # get precision
      alpha[t] <- tau_r / (tau_0 + (t+1)*tau_r) # get learning rate
      
      # update according to Rescorla-Wagner/ TD(0)
      mu[t+1] <- mu[t] + alpha[t] * (r[t] - mu[t]) 
  }
  mu
}
```

Then run simulations and plot. First showing each trajectory (in light grey) with mean, then showing mean and 95% CI. 

```{r}
# run sims 
n_sims <- 100
sims <- tibble::tibble(
  sim = 1:n_sims,
  t = map(1:n_sims, ~0:n),
  mu = map(sim, ~bayesian_update(n, v_true, mu_0, var_0, var_r))
  ) 
sims_unnested <- unnest(sims, c(mu, t))

# get mean and CI across trajectories at each time step
mean_mu <- sims_unnested %>%
  group_by(t) %>%
  summarise(
    mean_mu = mean(mu),
    sd_mu = sd(mu),
    ci_high = mean_mu + 1.96 * sd_mu,
    ci_low = mean_mu - 1.96 * sd_mu
    )

# show trajectories
sims_unnested |> 
  ggplot(aes(x = t, y = mu)) +
  geom_line(aes(group = sim), col = "grey", alpha = 0.25) +
  geom_line(data = mean_mu, aes(x = t, y = mean_mu), col = "black", lwd = 1) +
  scale_y_continuous(breaks = seq(0, 15, 2.5)) +
  labs(y = expression(mu[t]), x = "Time (t)") +
  geom_hline(yintercept = v_true, col = "red", lty = 2) +  
  annotate("text", x = 2, y = 10.5, label = expression(v[true]), col = "red", fontface = "bold")


# show CI as shaded region
ggplot(mean_mu, aes(x = t, y = mean_mu)) +
  geom_ribbon(aes(ymin = ci_low, ymax = ci_high), alpha = 0.25) +
  geom_line(col = "black") +
  scale_y_continuous(breaks = seq(0, 15, 2.5)) +
  labs(y = expression(mu[t]), x = "Time (t)") +
  geom_hline(yintercept = v_true, col = "red", lty = 2) +
  annotate("text", x = 2, y = 10.5, label = expression(v[true]), col = "red", fontface = "bold")
```

\newpage 

### (b)

First, create function to output mean and SE of simulations.  

```{r}
get_sim_mean_se <- function(n_sims, n, v_true, mu_0, var_0, var_r) {
  sims <- tibble::tibble(
    sim = 1:n_sims,
    t = map(1:n_sims, ~ 0:n),
    mu = map(sim, ~bayesian_update(n, v_true, mu_0, var_0, var_r))
  ) 
  sims_unnested <- unnest(sims, c(mu, t))
  
  mean_mu <- sims_unnested %>%
    group_by(t) %>%
    summarise(
      mean_mu = mean(mu),
      sd_mu = sd(mu),
      ci_high = mean_mu + 1.96 * sd_mu,
      ci_low = mean_mu - 1.96 * sd_mu
    )
  mean_mu
}
```

## Varying prior variance

Now run simulations and plot for different values of prior variance. 

```{r}
# set params
params <- tidyr::expand_grid(n_sims, n, v_true, mu_0, var_0 = c(1, 25, 100), var_r = 16)

# run sims
sims <- params %>%
  mutate(
    results = pmap(
      list(n_sims = n_sims, n, v_true, mu_0, var_0, var_r), 
      get_sim_mean_se
      )
  )

# plot
sims |> 
  unnest(results) |> 
  ggplot(aes(x = t, y = mean_mu, group = var_0)) +
  geom_line(aes(col = as.factor(var_0))) +
  geom_ribbon(aes(ymin = ci_low, ymax = ci_high), alpha = 0.25) +
  scale_y_continuous(breaks = seq(0, 15, 2.5)) +
  labs(
    x = "Time (t)",
    y = expression(mu[t]), 
    col = expression(sigma[0]^2)
  ) +
  geom_hline(yintercept = v_true, col = "red", lty = 2) +
  annotate("text", x = 2, y = 10.5, label = expression(v[true]), col = "red", fontface = "bold")
```

## Varying likelihood variance

Now we run the simulations and plot for different likelihood (reward) variances.

```{r}
# set params
params <- tidyr::expand_grid(n_sims, n, v_true, mu_0, var_0, var_r = c(1, 25, 100))

# run sims
sims <- params %>%
  mutate(
    results = pmap(
      list(n_sims, n, v_true, mu_0, var_0, var_r),
      get_sim_mean_se
    )
  )

# plot
sims |> 
  unnest(results) |> 
  ggplot(aes(x = t, y = mean_mu, group = var_r)) +
  geom_line(aes(col = as.factor(var_r))) +
  geom_ribbon(aes(ymin = ci_low, ymax = ci_high), alpha = 0.25) +
  scale_y_continuous(breaks = seq(0, 15, 2.5)) +
  labs(
    x = "Time (t)",
    y = expression(mu[t]), 
    col = expression(sigma[r]^2)
  ) +
  geom_hline(yintercept = v_true, col = "red", lty = 2) +
  annotate("text", x = 2, y = 10.5, label = expression(v[true]), col = "red", fontface = "bold")
```
Because this is hard to see on the same plot (as the average posterior means are similar, with widely differing variances), we will plot these in separate panels.

```{r, fig.width=6}
# plot
sims |> 
  unnest(results) |> 
  ggplot(aes(x = t, y = mean_mu, group = var_r)) +
  geom_line(aes(col = as.factor(var_r))) +
  geom_ribbon(aes(ymin = ci_low, ymax = ci_high), alpha = 0.25) +
  facet_wrap(~var_r, labeller = label_both) +
  scale_y_continuous(breaks = seq(0, 15, 2.5)) +
  labs(
    x = "Time (t)",
    y = expression(mu[t]), 
    col = expression(sigma[r]^2)
  ) +
  geom_hline(yintercept = v_true, col = "red", lty = 2) +
  annotate("text", x = 4, y = 11, label = expression(v[true]), col = "red", fontface = "bold")
```

## Summary

From these analyses, we can see the following patterns:

1. Regardless of the prior variance, $\sigma_0^2$, or the likelihood variance, $\sigma_r^2$, we converge to the true value in expectation (this is more obvious with more timesteps).
2. The prior variance, $\sigma_0^2$, has a large impact on the rate of convergence. When the prior variance is high, the posterior mean converges to the true value more quickly (it is quicker to update beliefs when they are less certain).
3. The likelihood variance, $\sigma_r^2$, has a large impact on posterior variance. When this is high, posterior variance is high. The likelihood variance also has an effect on the rate of convergence, with lower likelihood variance leading to faster convergence of the posterior mean to the true value.